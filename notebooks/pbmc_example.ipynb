{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbc34c5-3c48-4d05-9b4d-dc8408042b76",
   "metadata": {},
   "source": [
    "# Tutorial: Transfer learning with a reference PBMC model\n",
    "\n",
    "This tutorial demonstrates how to train a reference HD-AE model and then use that model to embed new datasets not seen during training. In this tutorial we'll be considering a set of peripheral blood mononuclear cell (PBMC) data in nine batches using seven different technologies.\n",
    "\n",
    "---\n",
    "\n",
    "## Tutorial Goals:\n",
    "\n",
    "The following is walkthrough of how to use `HD-AE` for transfer learning tasks. Our goals here are:\n",
    "\n",
    "1. Train a reference HD-AE embedding model that learns a low-dimensional embedding space in which cells group by meaningful biological variations rather than nuisance factors (e.g. scRNA-seq technology)\n",
    "2. Use this reference model to embed new, previously unseen datasets\n",
    "\n",
    "---\n",
    "\n",
    "## The data:\n",
    "\n",
    "Our data consists of 30,975 cells, the expression levels of which were measured using seven different scRNA-seq technologies in nine batches. For convenience we provide a preprocessed version of the data available for download <a href=\"https://www.dropbox.com/s/bck6kksx34fbalh/pbmc.h5ad?dl=0\">here</a> that has already been filtered down to the 2000 most variable genes and has been normalized using the <a href=\"https://satijalab.org/seurat/\">Seurat R package</a>. The `HD-AE` codebase was designed for use with the <a href=\"https://scanpy.readthedocs.io/en/stable/\">scanpy</a> Python package, which we will use here to read in and visualize our data.\n",
    "\n",
    "First, we'll verify that the data has batch effects using the UMAP dimensionality reduction algorithm. Our provided dataset has been annotated with the technology used to collect it as well as ground-truth cell types, making it easy to confirm the presence batch effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0de2e-f2c3-488f-88c8-6532851b02a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from hd_ae.utils import set_seeds\n",
    "\n",
    "set_seeds() # To ensure reproducibility\n",
    "adata = sc.read(\"pbmc.h5ad\") # Make sure to download the data first from the link above! :)\n",
    "\n",
    "#sc.pp.neighbors(adata)\n",
    "#sc.tl.umap(adata)\n",
    "#sc.pl.umap(adata, color=['cell_type', 'study'], wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6857482-8c78-42dc-a7af-86e96941455d",
   "metadata": {},
   "source": [
    "In this tutorial, we'll be training our model using a subset of this data. We'll use seven of the nine batches (`source_adata`)for training our model, and hold out two of them (`target_adata`) for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58baf8c9-824b-4f42-997d-e89d6a518776",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_batches = [\"Drop-seq\", \"10x Chromium (v3)\"]\n",
    "\n",
    "source_adata = adata[~adata.obs['study'].isin(target_batches)]\n",
    "target_adata = adata[adata.obs['study'].isin(target_batches)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a515d-6901-48ea-b0d6-3a4a931a9974",
   "metadata": {},
   "source": [
    "From our UMAP plots, we can see the data appears to have batch effects, as it separates both by batch and cell type.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29a954-cebd-477f-908c-7016cdaad936",
   "metadata": {},
   "source": [
    "## HD-AE setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21770cd-ee1f-43bc-b8e0-c25fad0becd0",
   "metadata": {},
   "source": [
    "The low-level details of HD-AE have been abstracted away into a single `HD_AE` class that performs model training with just a few API calls. The `HD_AE` class requires at initialization time an AnnData object along with the name of the field used to denote each sample's batch of origin in the `obs` field of your AnnData object (`batch_key`). The values of HD-AE's hyperparameters can also be set here. We do them explicitly in this tutorial to illustrate the process, though these fields can also be left blank to use a reasonable default set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb37ba-6c23-48a8-a1d2-4d771f5d6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hd_ae import HD_AE\n",
    "\n",
    "hd_ae = HD_AE(\n",
    "    source_adata,\n",
    "    batch_key='study',\n",
    "    hidden_layer_sizes=[500, 250],\n",
    "    learning_rate = 1e-3,\n",
    "    embedding_dimension=50,\n",
    "    hsic_penalty = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a2209-49d3-4741-b643-5d8e1bb1c58b",
   "metadata": {},
   "source": [
    "## Training the model:\n",
    "\n",
    "Once defined, the model can be trained with a single call to the `train` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3865d8-b953-4c5e-8e2a-bbe0f9f23ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hd_ae.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd687a-835d-4bbd-b50c-ca648993db49",
   "metadata": {},
   "source": [
    "Once trained, the HD-AE model can be used to produce integrated sets of low-dimensional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d935e-3abd-4d58-97ef-391c8b43de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_embeddings = hd_ae.embed_data(source_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14b5e1-eb55-46bd-91bb-dceab9e3e534",
   "metadata": {},
   "source": [
    "Now we use UMAP plots to quickly verify that the embeddings of our training data are integrated across batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9fe95-a4ef-4f7a-971d-274f98d1247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(source_embeddings)\n",
    "sc.tl.umap(source_embeddings)\n",
    "sc.pl.umap(source_embeddings, color=['cell_type', 'study'], wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99553ed6-3647-4c4c-909d-85eda68bc96b",
   "metadata": {},
   "source": [
    "Based on our UMAP plots we can see that our training data clusters based on cell type and mixes across the different technologies.\n",
    "\n",
    "---\n",
    "\n",
    "Before we demonstrate HD-AE on a transfer learning task, we'll first save its parameters to disk. Doing so requires only a call to the `.save` function, along with the name of a directory to store the resulting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3677c-c211-4401-bdc7-478ad3eb2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_ae.save(\"pbmc_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d83d01-30d8-4771-9538-ac8f19feb3a8",
   "metadata": {},
   "source": [
    "### Transfer learning with HD-AE\n",
    "\n",
    "Now that we have a pretrained \"reference\" model, we can try embedding our target batches not seen during training. Ideally, we want the embeddings of our new test batches to still mix with the source batches provided by the model during training while still separating by cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891fa23-0cfc-4d1a-aa2e-f1d7dc0200f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = HD_AE.load(\"pbmc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952fe01-c66e-4410-b6df-84c7224cd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e34325-2f02-4d42-b71c-71032d0ddba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import concat\n",
    "\n",
    "full_adata = concat([source_adata, target_adata])\n",
    "full_embeddings = loaded_model.embed_data(full_adata)\n",
    "\n",
    "sc.pp.neighbors(full_embeddings)\n",
    "sc.tl.umap(full_embeddings)\n",
    "sc.pl.umap(full_embeddings, color=['cell_type', 'study'], wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2db33-9290-45de-b1e0-22291cab2311",
   "metadata": {},
   "source": [
    "From our UMAP plot we can see that our test batches do indeed mix with our source batches while separating by cell type!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
